---
title: ai-sundry

order: 1
author: zzys
date: 2025-01-2
category:
- 笔记
tag:
- ai
- 机器学习
---

### anaconda

- 激活环境：conda active xx

### SOTA

Sota实际上就是State of the arts 的缩写，指的是在某一个领域做的Performance最好的model，一般就是指在一些benchmark的数据集上跑分非常高的那些模型。

SOTA model：并不是特指某个具体的模型，而是指在该项研究任务中，目前最好/最先进的模型。
SOTA result：指的是在该项研究任务中，目前最好的模型的结果/性能/表现。

### 数据处理\特征工程

![](https://i-blog.csdnimg.cn/blog_migrate/df80dea51bb940174844dfdbf8a41d58.png)

#### 归一化 标准化

[归一化 （Normalization）、标准化 （Standardization）和中心/零均值化 （Zero-centered）-CSDN博客](https://blog.csdn.net/ytusdc/article/details/128504272)

标准化：

**消除量纲的影响：** 不同的特征可能有不同的单位（如米、千克、秒），标准化可以消除这些量纲的差异。

**提高算法性能：** 对于依赖于距离的算法（如 KNN、SVM 等）或基于梯度下降优化的算法（如神经网络、线性回归），标准化可以加快收敛速度。

**处理偏态分布：** 标准化可以帮助数据更接近正态分布，方便进一步分析。

### 机器学习问题

- 回归（根据历史信息进行预测）
- 分类
- 聚类
- 生成式

### 机器学习分类

#### 监督学习

是使用足够多的带有label的数据集来训练模型，数据集中的每个样本都带有人工标注的label。通俗理解就是，模型在学习的过程中，“老师”指导模型应该向哪个方向学习或调整。

- **线性回归**（Linear Regression）：用于回归任务，预测连续的数值。
- **逻辑回归**（Logistic Regression）：用于二分类任务，预测类别。
- **支持向量机**（SVM）：用于分类任务，构建超平面进行分类。
- **决策树**（Decision Tree）：基于树状结构进行决策的分类或回归方法。

#### 无监督学习

是指训练模型用的数据没有人工标注的标签信息，通俗理解就是在“没有老师指导”的情况下，靠“学生”自己通过不断地探索，对知识进行归纳和总结，尝试发现数据中的内在规律或特征，来对训练数据打标签。

- **K-means 聚类**：通过聚类中心将数据分组。

**半监督学习**：是在只能获取少量的带label的数据，但是可以获取大量的的数据的情况下训练模型，让学习器不依赖于外界交互，自动地利用未标记样本来提升学习性能，半监督学习是监督学习和非监督学习的相结合的一种学习方法。

#### 强化学习	

(Reinforcement Learning）一种机器学习的方法，通过从外部获得激励来校正学习方向从而获得一种自适应的学习能力。

**具备人类反馈的强化学习 (RLHF)**：在 [RLHF](https://www.ibm.com/cn-zh/topics/rlhf) 中，人类用户通过评估来响应生成的内容，此类评估可以帮助模型进行更新，以提高其准确性和相关性。通常，RLHF 涉及相关人员根据相同的提示对不同的输出进行“评分”。但这也可以很简单，比如让人员输入文字或通过语音回复聊天机器人或虚拟助手，以纠正其输出结果。

### 迁移学习

迁移学习通俗来讲，就是运用已有的知识来学习新的知识，核心是找到已有知识和新知识之间的相似性，用成语来说就是举一反三。由于直接对目标域从头开始学习成本太高，我们故而转向运用已有的相关知识来辅助尽快地学习新知识。比如，已经会下中国象棋，就可以类比着来学习国际象棋；已经会编写Java程序，就可以类比着来学习C#；已经学会英语，就可以类比着来学习法语；等等。世间万事万物皆有共性，如何合理地找寻它们之间的相似性，进而利用这个桥梁来帮助学习新知识，是迁移学习的核心问题。

### 基本机器学习算法

#### 线性回归算法(Linear Regression)

单变量回归，多变量回归

#### 支持向量机算法(Support Vector Machine,SVM)

寻找一个维度为m-1**决策超平面**将n个维度为m的数据区分为两类数据。

将距离超平面最近的距离成为**间隔**，训练的目标是找到最大间隔。距离超平面最近的点称为**支持向量**

**软硬间距**



**核函数**



### 神经网络

MLP 全连接

AlexNet

VGG

CNN ResNet 

RNN LSTM

GAN

VAE

Transformer

#### 分类问题

采用`one-hot`对类别进行编码，最后输出一个向量，对其进行`softmax`表示预测概率。

采用交叉熵作为损失函数，相较于MSE，更容易收敛。

#### 激活函数

Relu

sigmoid

#### 优化

当loss无法继续下降时，考虑局部最小，马鞍点，LR设置不当，batch_size设置不当。

##### epoch

训练的轮次，一个epoch就已经看过了完整的一遍训练数据

##### batch_size

每个batch更新一次参数

<img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/ce719b7acfc65c3864a1ca2cebe5fa4b.png" alt="image-20250121141948250" style="zoom:50%;" />

##### momentum

翻译为动量，即不仅考虑本次的梯度方向，还考虑上一次的更新方向，迭代下来就是第`i`次更新不仅看第`i`次的梯度，还要看以往所有梯度，通过一个系数来调整影响效果，`m`更新的方向由上一次的动量和当前动量的矢量和构成，其中`λ`是超参数。

<img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/ba1b8f4bd1e07a0617491756fbdbd70f.png" alt="image-20250121142700302" style="zoom: 25%;" />

##### LR（learning rate）

学习率乘以负的梯度，计算每次参数更新的大小。

尝试**自动调整学习率**以便更快更好的收敛，引入一个新的超参数`σ`：

$θ^{t+1}_{i} = θ^{t+1}_{i} - \frac{\eta}{\sigma^{t}_{i}}g^{t}_{i}$

`σ`最常用的设置方式为RMSProp，引入超参数`α`，设置方式如下：

$\sigma^{t}_{i}=\sqrt{\alpha(\sigma^{t-1}_{i})^{2}+(1-\alpha)(g^{t}_i{})^{2}}$

其中当`α`接近一时，`σ`的变化取决于当前的梯度计算，梯度越大，更新的步伐就会变小。

为了避免在收敛中突然出现的发散行为，引入**warm up**策略，将`η`和时间相关联，整体呈现先上升后下降的趋势。

总结：RMSProp + momentum + warm up

<img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/1b44454d94cb75246946d97f46683635.png" alt="image-20250122130136227" style="zoom:50%;" />

##### Adam



##### SGD



##### 正则化

正则化即为对学习算法的修改，旨在减少泛化误差而不是训练误差。正则化的策略包括：

1. 约束和惩罚被设计为编码特定类型的先验知识。
2. 偏好简单模型。
3. 其他形式的正则化，如：集成的方法，即结合多个假说解释训练数据。

#### LOSS

分类问题常用 [交叉熵损失函数](https://blog.csdn.net/chao_shine/article/details/89925762)

回归用均方差（MSE）

#### 问题

过拟合：泛化误差大，泛化能力弱

欠拟合：训练误差大，模型过于简单

##### 局部点

一阶偏导数为零，不一定陷入了局部最小值，马鞍点的一阶偏导数也是零，通过对L(θ)进行泰勒展开计算Hessian矩阵（由二阶偏导组成的矩阵，用于判断极值点类型）。泰勒展开公式如下：

$L(θ) \approx L(θ^{\prime}) + (θ - θ^{\prime})^{T}g + \frac{1}{2}(θ - θ^{\prime})^{T}H(θ - θ^{\prime})$

其中，在局部点和马鞍点中`g`向量都为零，而H矩阵，即为hessian矩阵，若其正定，即为局部最小值点，负定即为局部最大值，故为：

$L(θ) \approx L(θ^{\prime}) + \frac{1}{2}(θ - θ^{\prime})^{T}H(θ - θ^{\prime})$

同时，hessian矩阵也可指出更新的方向，若`H`矩阵有特征向量与特征值：

$H \mu=\lambda \mu$

则上述泰勒展开公式可进一步写作：

$L(θ) \approx L(θ^{\prime}) + \mu^{T}H\mu$

$L(θ) \approx L(θ^{\prime}) + \mu^{T}\lambda\mu$

$L(θ) \approx L(θ^{\prime}) + \lambda||\mu||^{2}$

这样根据该特征值的正负，就可使得Loss进一步降低

### 大模型

#### 预训练

通过大量数据和算法，AI模型学会识别和生成规律。模型参数在此过程中不断调整，以最小化预测与实际值之间的误差，从而使其具备适应各种任务的学习能力，涵盖图像识别到自然语言处理等多个领域。

##### 微调（fine-tuning）

微调其实讲的是利用原有模型参数（“知识”）初始化现有模型，在此基础上继续train自己的model（“再加工”）。说人话就是把现成的模型略加修改然后再作少量training，主要用于样本数量不足的情形。

##### 指令微调

（Instruction FineTuning），针对已经存在的预训练模型，给出额外的指令或者标注数据集来提升模型的性能，如P-tuning， prompt-tuning，prefix-tuning。

##### 增量微调

是指在神经网络中增加额外的层，如lora，adapter。

#### 推理

建立在训练完成的基础上，将训练好的模型应用于新的、未见过的数据。模型利用先前学到的规律进行预测、分类或生成新内容，使得AI在实际应用中能够做出有意义的决策，例如在医疗诊断、自动驾驶和自然语言理解等领域。

在推理阶段，训练好的模型被用于对新的、未见过的数据进行预测或分类。大型模型在推理阶段可以处理各种类型的输入，并输出相应的预测结果。推理可以在生产环境中进行，例如在实际应用中对图像、语音或文本进行分类，也可以用于其他任务，如语言生成、翻译等。

这两个关键能力的有机结合使得AI模型成为企业数据分析和决策的强大工具。

通过训练，模型从历史数据中提取知识；
通过推理，将这些知识应用于新场景，从而做出智能决策。

### RAG

**RAG（Retrieval-Augmented Generation，检索增强生成），RAG**是一种 AI 框架，它将传统信息检索系统（例如数据库）的优势与生成式大语言模型 (LLM) 的功能结合在一起。

检索：检索是RAG流程的第一步，从预先建立的**知识库**中检索与问题相关的信息。这一步的目的是为后续的生成过程提供有用的上下文信息和知识支撑。

增强：RAG中增强是将**检索到的信息**用作生成模型（即大语言模型）的**上下文输入**，以增强模型对**特定问题**的理解和回答能力。这一步的目的是将外部知识融入生成过程中，使生成的文本内容更加丰富、准确和符合用户需求。通过增强步骤，LLM模型能够充分利用外部知识库中的信息。



### diffsion



### VAE



### 自编码器



### glove word2vec

### GAN

### R-CNN

### LSTM

### ResNet

### CLIP

### 评价标准

#### 混淆矩阵 TP TN FN FP

[Confusion matrix - Wikipedia](https://en.wikipedia.org/wiki/Confusion_matrix)

常用于有监督学习，处理分类问题。

第一个字母表示是否正确预测，第二个字母表示预测的类别。

如果有癌症记为一`positive`，无癌症记为零`negative`，则：

| 实际\预测     | 有癌症(1) | 无癌症(0) |
| ------------- | --------- | --------- |
| **有癌症(1)** | TP        | FN        |
| **无癌症(0)** | FP        | TN        |

对角线的两个元素`TP TN`就是预测正确的数量。

#### 准确率 (Accuracy)

即在所有的预测中中判断正确的：

$Accuracy=\frac{TP+TN}{Total\  Samples}$

当数据集类别不平衡时，准确率可能会产生误导。例如，在一个极端类别不平衡的情况下（例如，99% 样本为负类），即使模型总是预测为负类，它也能得到很高的准确率，但实际模型性能可能很差。

#### 精确率 (Precision)

所有判断为positive样本中，真正为positive的比例：

$Precision=\frac{TP}{TP + FP}$

适用于positive预测错误代价高的场景，要降低预测错误的概率，预测错误如将正常邮件(negative)识别为垃圾邮件(positive)，可以承受少量漏报。

####  召回率 (Recall)

即所有真正为positive的样本中，真正为positive的比例：

$Recall=\frac{TP}{TP + FN}$

适用于漏报代价高的场景，要降低漏报的概率，如入侵检测，癌症检测等。

####  F1-score

F1-score 是精确率和召回率的调和平均数，综合考虑了精确率和召回率的平衡。

$F1-score = 2*\frac{Precision×Recall}{Precision+Recall}$

### 常见数学公式

#### 方差

每个数值到平均值的差的平方和

#### 标准差

即方差的开根

#### 凸优化
